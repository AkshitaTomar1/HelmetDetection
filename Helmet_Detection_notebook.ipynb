{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70474802",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install -q albumentations pycocotools dill\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0d21e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, models, transforms as T\n",
    "from torchvision.transforms import functional as FT\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import copy\n",
    "import math\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import albumentations as A\n",
    "import matplotlib.pyplot as plt\n",
    "from pycocotools.coco import COCO\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "from torchvision.utils import draw_bounding_boxes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70df3d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6460f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "dataset_path = \"/content/drive/MyDrive/helmet-detection-dataset\"  # Adjust this if your dataset is in a different location\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec555acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transforms(train=False):\n",
    "    if train:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(600, 600),\n",
    "            A.HorizontalFlip(p=0.3),\n",
    "            A.VerticalFlip(p=0.3),\n",
    "            A.RandomBrightnessContrast(p=0.1),\n",
    "            A.ColorJitter(p=0.1),\n",
    "            ToTensorV2()\n",
    "        ], bbox_params=A.BboxParams(format='coco'))\n",
    "    else:\n",
    "        transform = A.Compose([\n",
    "            A.Resize(600, 600),\n",
    "            ToTensorV2()\n",
    "        ], bbox_params=A.BboxParams(format='coco'))\n",
    "    return transform\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7268a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HelmetDetection(datasets.VisionDataset):\n",
    "    def __init__(self, root, split='train', transform=None, target_transform=None, transforms=None):\n",
    "        super().__init__(root, transforms, transform, target_transform)\n",
    "        self.split = split\n",
    "        self.coco = COCO(os.path.join(root, split, \"_annotations.coco.json\"))\n",
    "        self.ids = list(sorted(self.coco.imgs.keys()))\n",
    "        self.ids = [id for id in self.ids if (len(self._load_target(id)) > 0)]\n",
    "    \n",
    "    def _load_image(self, id: int):\n",
    "        path = self.coco.loadImgs(id)[0]['file_name']\n",
    "        image = cv2.imread(os.path.join(self.root, self.split, path))\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        return image\n",
    "\n",
    "    def _load_target(self, id):\n",
    "        return self.coco.loadAnns(self.coco.getAnnIds(id))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        id = self.ids[index]\n",
    "        image = self._load_image(id)\n",
    "        target = copy.deepcopy(self._load_target(id))\n",
    "        boxes = [t['bbox'] + [t['category_id']] for t in target]\n",
    "        \n",
    "        if self.transforms is not None:\n",
    "            transformed = self.transforms(image=image, bboxes=boxes)\n",
    "            image = transformed['image']\n",
    "            boxes = transformed['bboxes']\n",
    "        \n",
    "        new_boxes = []\n",
    "        for box in boxes:\n",
    "            xmin = box[0]\n",
    "            xmax = xmin + box[2]\n",
    "            ymin = box[1]\n",
    "            ymax = ymin + box[3]\n",
    "            new_boxes.append([xmin, ymin, xmax, ymax])\n",
    "        \n",
    "        boxes = torch.tensor(new_boxes, dtype=torch.float32)\n",
    "        \n",
    "        targ = {}\n",
    "        targ['boxes'] = boxes\n",
    "        targ['labels'] = torch.tensor([t['category_id'] for t in target], dtype=torch.int64)\n",
    "        targ['image_id'] = torch.tensor([id])\n",
    "        targ['area'] = (boxes[:, 3] - boxes[:, 1]) * (boxes[:, 2] - boxes[:, 0])\n",
    "        targ['iscrowd'] = torch.tensor([t['iscrowd'] for t in target], dtype=torch.int64)\n",
    "        return image.div(255), targ\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f351e6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "coco = COCO(os.path.join(dataset_path, \"train\", \"_annotations.coco.json\"))\n",
    "categories = coco.cats\n",
    "classes = [i[1]['name'] for i in categories.items()]\n",
    "n_classes = len(classes)\n",
    "print(\"Classes:\", classes)\n",
    "train_dataset = HelmetDetection(root=dataset_path, transforms=get_transforms(True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08850d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = train_dataset[2]\n",
    "img_int = torch.tensor(sample[0] * 255, dtype=torch.uint8)\n",
    "plt.imshow(draw_bounding_boxes(\n",
    "    img_int, sample[1]['boxes'], [classes[i] for i in sample[1]['labels']], width=4\n",
    ").permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac6295a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.detection.fasterrcnn_mobilenet_v3_large_fpn(pretrained=True)\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, n_classes)\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44180081",
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_fn(batch):\n",
    "    return tuple(zip(*batch))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=2, collate_fn=collate_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208a3404",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.01, momentum=0.9, nesterov=True, weight_decay=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e381a356",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, loader, device, epoch):\n",
    "    model.train()\n",
    "    all_losses = []\n",
    "    all_losses_dict = []\n",
    "    \n",
    "    for images, targets in tqdm(loader):\n",
    "        images = list(image.to(device) for image in images)\n",
    "        targets = [{k: torch.tensor(v).to(device) for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        loss_value = losses.item()\n",
    "        \n",
    "        if not math.isfinite(loss_value):\n",
    "            print(f\"Loss is {loss_value}, stopping training\")\n",
    "            return\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        all_losses.append(loss_value)\n",
    "        all_losses_dict.append({k: v.item() for k, v in loss_dict.items()})\n",
    "    \n",
    "    all_losses_df = pd.DataFrame(all_losses_dict)\n",
    "    print(\"Epoch {}, loss: {:.6f}\".format(epoch, np.mean(all_losses)))\n",
    "    print(all_losses_df.mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59b4a591",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    train_one_epoch(model, optimizer, train_loader, device, epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ce67dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model, \"/content/drive/MyDrive/helmet-detection-trained-model.pt\")\n",
    "print(\"Model saved to Google Drive.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
